{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be91071",
   "metadata": {},
   "source": [
    "### Q) What is Naive Bayes algorithm?\n",
    "Naive Bayes is a supervised learning algorithm based on Bayes' theorem. It assumes that all features in the dataset are independent of each other, hence the \"naive\" assumption. It is widely used for classification tasks and is known for its simplicity and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34297407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38707d0d",
   "metadata": {},
   "source": [
    "### Q) What are the types of Naive Bayes algorithms?\n",
    "\n",
    "There are three common types of Naive Bayes algorithms:\n",
    "a) Gaussian Naive Bayes: Assumes that continuous features follow a Gaussian distribution.\n",
    "b) Multinomial Naive Bayes: Suitable for discrete features, such as text classification where features represent word counts.\n",
    "c) Bernoulli Naive Bayes: Used when features are binary, indicating the presence or absence of a certain feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2aa201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31dbfa51",
   "metadata": {},
   "source": [
    "### Q) What is the main assumption made by Naive Bayes?\n",
    "1) All features are independent to each other and all features are equally important.\n",
    "\n",
    "\n",
    "2) All features contributes equal to the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9d138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ec8103c",
   "metadata": {},
   "source": [
    "### Q) How does Naive Bayes handle missing data?\n",
    "Naive Bayes can handle missing data by ignoring the instance with missing values during the training phase. During the prediction phase, if a feature value is missing, it can be ignored or replaced with a suitable value (e.g., the mean or mode of that feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c0597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea5ede1c",
   "metadata": {},
   "source": [
    "### Q) How does Naive Bayes handle continuous numerical features?\n",
    "Gaussian Naive Bayes is specifically designed to handle continuous numerical features. It assumes that the values of each feature follow a Gaussian distribution. During training, it estimates the mean and standard deviation of each feature for each class. During prediction, it uses these parameters to compute the likelihood of a given feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81d8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56b00994",
   "metadata": {},
   "source": [
    "### Q) What is Laplace smoothing (additive smoothing) in Naive Bayes?\n",
    "Laplace smoothing is a technique used in Naive Bayes to handle the problem of zero probabilities. It prevents the multiplication of probabilities from becoming zero by adding a small value (usually 1) to both the numerator and denominator of the probability estimation formula. This helps to avoid zero probabilities and handle unseen features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efbc762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01bd20bc",
   "metadata": {},
   "source": [
    "### Q) Can Naive Bayes handle continuous target variables?\n",
    "Naive Bayes is primarily used for classification tasks, which involve predicting discrete class labels. It is not suitable for directly handling continuous target variables. However, it can be adapted for regression tasks by discretizing the target variable into bins or using other techniques like Gaussian Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82de74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e66c4e05",
   "metadata": {},
   "source": [
    "### Q) What are the advantages of Naive Bayes?\n",
    "\n",
    "a) Naive Bayes is simple and easy to understand.\n",
    "\n",
    "b) It performs well with large feature spaces.\n",
    "\n",
    "c) It can handle both categorical and numerical features.\n",
    "\n",
    "d) It is computationally efficient and scales well with large datasets.\n",
    "\n",
    "e) It provides probabilistic predictions and can handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547426fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74d5eaa0",
   "metadata": {},
   "source": [
    "### Q) What are the limitations of Naive Bayes?\n",
    "\n",
    "a) Naive Bayes assumes independence between features, which may not be true in real-world scenarios.\n",
    "\n",
    "b) It can be sensitive to irrelevant or correlated features.\n",
    "\n",
    "c) The quality of predictions heavily relies on the quality of the training data.\n",
    "\n",
    "d) It cannot learn interactions between features.\n",
    "\n",
    "e) The \"zero-frequency problem\" can occur when a feature has not been observed in a particular class, resulting in zero probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01047363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
