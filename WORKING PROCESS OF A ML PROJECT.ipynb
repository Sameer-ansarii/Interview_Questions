{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d59654e",
   "metadata": {},
   "source": [
    "## Steps Involved in EDA\n",
    "\n",
    "**Note:- There is no fix step in EDA, we perform EDA by our own mind and logic and if the number of variables are more, then we seprate numerical and categorical columns and works on it seprately.**\n",
    "\n",
    "**While perfroming EDA write inplace=True in your codes, otherwise the thing you want to perfrom, it will done only on temporary basis or varible of EDA not on original dataset.**\n",
    "\n",
    "1) Understand the data, each and every column carefully.\n",
    "\n",
    "\n",
    "2) Import required libraries and import the fata and look how data looks like by using df.head() and check for sample by using df.sample(6).\n",
    "\n",
    "\n",
    "3) df.shape, check the shape of data.\n",
    "\n",
    "\n",
    "4) df.columns, check the names of column, if you want to customized the column names you can do.\n",
    "\n",
    "\n",
    "5) df.info(), check data types and null values in columns.\n",
    "\n",
    "\n",
    "6) df.isna().sum()/len(df)*100, check for the null percentages in columns, if nulls are present then don't remove now.\n",
    "\n",
    "\n",
    "7) Remove Irrelevant columns i.e index, date, etc. which is not required for analysis and recheck that columns were removed or not by df.columns.\n",
    "\n",
    "\n",
    "8) df.duplicated().sum(), check for the duplicates, if present then remove these by using df.drop_duplicates() and check again using df.duplicated().sum() that duplicates are removed or not and look for the df.shape for confirmation.\n",
    "\n",
    "\n",
    "9) df.describe(), check statistical summary of data for the purpose of understanding and data mining.\n",
    "\n",
    "\n",
    "10) df.corr(), check correlation between variables for the purpose of understanding and data mining.\n",
    "\n",
    "\n",
    "11) df.dropna('target variable') because impute the values of target variable is not a correct approach, do this if needed.\n",
    "\n",
    "\n",
    "12) After droping rows theck that how much data is lost. Compare df.shape before and after droping rows of target variable.\n",
    "\n",
    "\n",
    "13) df.drop(\"columns\"), drop columns which having high percentages of null or those columns which are irrelavant in analysis i.e (Serial Number, Index, etc.), do this if needed.\n",
    "\n",
    "\n",
    "14) Check for the null value percentage again, if null values are present then treat it.\n",
    "\n",
    "\n",
    "15) If null values present in numerical column then check for the outliers, if outliers are not present impute them with means and if outliers are present then fill it with median and if the null values are present in the categorical column then fill it mode. **Imputation of null values also depends on problem statement and we need to discuss it with client itself and fill null values according to him**.\n",
    "\n",
    "\n",
    "16) After imputing nulls check the data types of columns. If any column has suspicious data type correct it.\n",
    "\n",
    "\n",
    "17) Check the uniques values of all variables and check that whether there is any suspicious value present in any variable or not, if present then treat it.\n",
    "\n",
    "\n",
    "18) After doing all these steps recheck whole dataframe by df.shape, df.columns, df.info(), df.isnull().sum(), df.duplicated.sum() and unique values of all variables. If anything looks suspicious then treat it.\n",
    "\n",
    "\n",
    "19) Checking for outliers using box plot if outliers are present than remove them using IQR Method.\n",
    "\n",
    "\n",
    "20) If outliers are more, then use Z-Score method to remove outliers because in IQR method data will be lost more than Z-Score method.\n",
    "\n",
    "\n",
    "21) Checking for the outliers again using boxplot and check outliers were removed or not.\n",
    "\n",
    "\n",
    "22) df_copy = df.copy(), make a copy of dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e6fec",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee819e9",
   "metadata": {},
   "source": [
    "## Steps involved in Feature Engineering.\n",
    "\n",
    "### Check colinearity between variables to avoid model from overfitting.\n",
    "\n",
    "1) df.corr() \n",
    "\n",
    "\n",
    "2) correlation matrix for understanding about the variables.\n",
    "\n",
    "\n",
    "3) Write report which variables are highly correlated. \n",
    "\n",
    "**Check only independent variables which are highly positive or inverse correlated. Don't consider that variable which are highly correlated with target variable.**\n",
    "\n",
    "4) Those correlation of highly correlated variables with target variables.\n",
    "\n",
    "\n",
    "5) Among pair of highly correlated variable, drop that variable which having lowest correlation with target variable.\n",
    "\n",
    "\n",
    "6) After dropping check correlation matrix again for recheck.\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "### Feature Encoding\n",
    "\n",
    "1) Seprate the categorical columns.\n",
    "\n",
    "\n",
    "2) Check all the uniques of categorical variables.\n",
    "\n",
    "\n",
    "3) If unique values are nomial and less in number then apply one hot encoding on those features.\n",
    "\n",
    "\n",
    "4) If unique value are nomial but more in number then apply target mean encoding.\n",
    "\n",
    "\n",
    "5) If unique value are ordinal then apply df.replace or label encoding.\n",
    "\n",
    "\n",
    "6) After applying encoding check the data frame. \n",
    "\n",
    "\n",
    "7) Check data types of variables, if anything is suspicious correct it.\n",
    "\n",
    "**Note:- apply encoding directly in dataframe.**\n",
    "\n",
    "-----------------------------------------------\n",
    "\n",
    "### Checking Distribution of data.\n",
    "\n",
    "**check skewness of dependent variables only**\n",
    "\n",
    "1) df.shape, check the number of rows.\n",
    "\n",
    "\n",
    "2) Check the number of correct bin sizes using sturges_rule and put number of rows in this formula.\n",
    "\n",
    "\n",
    "3) Creating histogram of all float and integer variables.\n",
    "\n",
    "\n",
    "4) Check df.skew() of all that variables.\n",
    "\n",
    "\n",
    "5) Prepare a report that which variables are not skewed, moderate skewed, skewed.\n",
    "\n",
    "\n",
    "6) Analyze that why they are skewed and write a conclusion about variables which are skewed.\n",
    "\n",
    "\n",
    "**Transform data using transformation techniques in case of regression only not in classification.**\n",
    "\n",
    "\n",
    "7) Use different transformation techniques on different variables according to need.\n",
    "\n",
    "|Transformation|\tDirection of skewness|\tEffectiveness|\n",
    "|-------------|-------------------------|-----------------|\n",
    "|Log transformation|\tRight\t|Very effective|\n",
    "|Square root transformation|\tLeft\t|Very effective|\n",
    "|Reciprocal transformation|\tRight|\tEffective|\n",
    "|Exponential transformation\t|Left\t|Effective|\n",
    "|Box-Cox transformation|\tBoth|\tVaries|\n",
    "\n",
    "8) Check the distribution and skewness score again and write a report.\n",
    "\n",
    "-------------------------\n",
    "\n",
    "### Diving data into train and test set\n",
    "\n",
    "1) Seprate independent variable and target variable.\n",
    "\n",
    "\n",
    "2) Import train_test_split and perform it on both train and test data.\n",
    "\n",
    "\n",
    "**Note:- Always write random_state=42 in code.**\n",
    "\n",
    "3) X_train.shape, y_train.shape, to check the shape\n",
    "\n",
    "\n",
    "4) X_test.shape, y_test.shape, to check the shape\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "### Feature Scaling \n",
    "\n",
    "1) Check the uniques of all variables and identify columns needs to be scale.\n",
    "\n",
    "**Note:- Exclude binary variables in case of appyling standard scaler, min max scaler and robust scaler and exclude variables upto 4 unique values in case of standard scaler only.** \n",
    "\n",
    "**Scaling is not perform on target variable.**\n",
    "\n",
    "**Apply same scaler on all columns which needs scaling.** \n",
    "\n",
    "\n",
    "2) If most of the variables are normally distributed then apply standard scaler. The range of standard scaler is +3 to -3, if data doen't consists outliers.\n",
    "\n",
    "\n",
    "3) If data is in bounded range i.e (you known that values of this variable is not goes high and low beyond this range) then apply min max scaler. The range of min max scaler is -1 to +1.\n",
    "\n",
    "\n",
    "4) If data contains outliers and outliers are important and not to be dropped so apply robust scaling. The range of robust scaling is not fixed.\n",
    "\n",
    "\n",
    "5) Check the X_train.head() to confrim that scaling is done or not.\n",
    "\n",
    "**Scale the values of X_train only not X_test because we assumed that X_test value are values of real world scenario.**\n",
    "\n",
    "---------------------------------------------\n",
    "\n",
    "### Check Class Imbalance in case of classification\n",
    "\n",
    "**Note:- Give that parameter while applying any resampling technique, random_state=42.**\n",
    "\n",
    "1) Check value_counts() of target variable\n",
    "\n",
    "\n",
    "2) Plot a graph of it\n",
    "\n",
    "\n",
    "3) Check class imbalance ratio\n",
    "\n",
    "\n",
    "4) If class imbalancing problem is present then deal with it otherwise proceed with next step which is feature selection\n",
    "\n",
    "\n",
    "5) According to need apply various Class imbalancing techniques like SMOTE, ADASYN, etc.\n",
    "\n",
    "\n",
    "6) Apply multiple techniques and build random forest model after applying any technique.\n",
    "\n",
    "\n",
    "7) Check performance of model on train and test data both after applying any technique.\n",
    "\n",
    "\n",
    "8) Select a technique which gives better result among all.\n",
    "\n",
    "\n",
    "9) Write report why you select this technique \n",
    "\n",
    "\n",
    "10) Apply this technique again.\n",
    "\n",
    "\n",
    "**Note:- In case when all techniques provides almost similar result and overfits the model then go with smote because it is less sensitive to overfitting.**\n",
    "\n",
    "--------------------\n",
    "\n",
    "### Feature Selection Using Random Forest Importance method\n",
    "\n",
    "1) Make a base model and create a data frame of feature importance in descending order.\n",
    "\n",
    "\n",
    "2) Make a graph of cumulative feature importance against the number of features.\n",
    "\n",
    "\n",
    "3) select a optimal number of features and update X_train, X_test and check their shape for confirmation.\n",
    "\n",
    "\n",
    "4) Check the selected top features by X_train.columns\n",
    "\n",
    "-------------------------\n",
    "\n",
    "### Check multi-colinearity between variables to avoid model from overfitting.\n",
    "\n",
    "1) Check for the VIF.\n",
    "\n",
    "\n",
    "2) If the variables are having VIF Values more than 5 then drop them one by one and check VIF values again and again repeat this process untillall variables have VIF under 5.\n",
    "\n",
    "**Note:- Remove high VIF value variables from both sets trainning and testing.**\n",
    "\n",
    "3) Check the column names and shape of data of training and test set both for confirmation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8cb428",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385b81d",
   "metadata": {},
   "source": [
    "## Model Building:-\n",
    "\n",
    "**Note:- give this parameter in every individual model random=42 and n_jobs=1.**\n",
    "\n",
    "1) Import and apply algorithms i.e simple algorithms, bagging and boosting algorithms.\n",
    "\n",
    "\n",
    "2) Evaulate their performance on training and test data both.\n",
    "\n",
    "**Select that algorithm which is generalized and according to problem statement thier respective performance metric is maximum among all.**\n",
    "\n",
    "3) If you select a simple algorithm then make a ensemble of it and elaluate it's performance on both sets. If ensemble performes better select that other select simple.\n",
    "\n",
    "4) If simple provides better results make a model of it seprately.\n",
    "\n",
    "\n",
    "5) In case you select an ensemble model at step no. 2 then make a seprate model of it.\n",
    "\n",
    "---------------\n",
    "\n",
    "## Hyperparameter tunning\n",
    "\n",
    "1) If dataset is large then use randomizedSearchCV otherwise use GridSearch CV.\n",
    "\n",
    "\n",
    "2) After hyperparameter tunning, check results by using best_estimator_.predict(X_train) and best_estimator_.predict(X_test).\n",
    "\n",
    "\n",
    "3) Evaulation results on both sets, train and test. If  best_estimator provides better results then build model using that estimators and use object name as model_tunned and gives random_state=42.\n",
    "\n",
    "\n",
    "4) Evaulate it's result on test and train data.\n",
    "\n",
    "**If hyperparameters provides better result than select model with best_estimators other select model with existing parameters.**\n",
    "\n",
    "-------------------\n",
    "\n",
    "## Cross Validation\n",
    "\n",
    "1) Import and perfrom cross validation of that metric which is most important according problem statement otherwise perform cross validation on multiple performance metrics.\n",
    "\n",
    "--------------------\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "1) Evaulate model on train and test data both. \n",
    "\n",
    "---------------------------------\n",
    "\n",
    "## Feature Importance/ Check Coeffcients \n",
    "\n",
    "**In case you select a tree base algorithm then check the feature importance otherwise check coefficients in case of linear and logistic regression.**\n",
    "\n",
    "1) Check the feature importance or coefficients.\n",
    "\n",
    "\n",
    "2) Make a plot of it.\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "## Save model in system\n",
    "\n",
    "1) Import joblib and save model.\n",
    "\n",
    "**Save model using joblib rather than pickle because it works faster than pickle in case of model with large size.**\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "## Making Report\n",
    "\n",
    "1) Write the whole process of model building tills evaulation. Write in report that why you select a model what are the steps you perform you increase the performance of a model and all major and minor steps you perform on model building. Write all these steps, step by step.\n",
    "\n",
    "\n",
    "2) Write the model summary of performance metrics on train and test data both.\n",
    "\n",
    "\n",
    "3) Write a list of importance features and coefficients on which target variable depends the most.\n",
    "\n",
    "---------------------------\n",
    "\n",
    "## Write the conclusion or your suggestion to deal with problem statement while considering the result of analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b1796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "689f07aa",
   "metadata": {},
   "source": [
    "# In case of Classification\n",
    "\n",
    "1) After performing hyperparameter tunning then check for the thresholds.\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "## Finding Optimal Threshold\n",
    "\n",
    "1) Create a data frame of actual labels and predicted labels along with their probability of train data and analyze the threshold of 0.5 works correct or not. \n",
    "\n",
    "**Usually 0.5 threshold is not works better.**\n",
    "\n",
    "2) Check the evaulation metrics such as accuracy, balance accuracy, precision, recall,f1 score on thresholds [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]. Analyze for which threshold point the performance metric value is high as per the given problem statement.\n",
    "\n",
    "\n",
    "3) Check perfromance metrics of below and high 10 thresholds from selected threshold i.e selected threshold is 0.3 to check the metrics on all thresholds between 0.2 to 0.4.\n",
    "\n",
    "\n",
    "4) Select that threshold for which metric value if maximum according given problem statement.\n",
    "\n",
    "\n",
    "5) Plot the graph of Accuracy, Sensitivity, specitivity against all possible thresholds in case when any of these 3 are required for analysis otherwise plot a graph of Accuracy, Sensitivity, specitivity, f1 score against all possible thresholds if f1 score is required for the analysis. \n",
    "\n",
    "\n",
    "6) Select that threshold where all lines of these metrics intersects each other because that threshold is generalized and stable threshold. \n",
    "\n",
    "\n",
    "7) In case the threshold value comes same by plotting graph and evaulating performance metric on various threshold then evaulate model by setting that threshold as optimal threshold on train and test data both.\n",
    "\n",
    "**Usually these threshold values are different**\n",
    "\n",
    "8) Otherwise evaluate model on both tresholds on train and test data.\n",
    "\n",
    "**Note:- ROC-AUC Curve is made on train data because we have to check the quality of model and this can be done on train data itself.** \n",
    "\n",
    "**If false positive error is most important to reduce than work on increasing the precision.**\n",
    "\n",
    "**If false negative error is most important to reduce than work on increasing the recall/sensitivity.**\n",
    "\n",
    "**If both are importance to reduce than work on increasing f1 score.** \n",
    "\n",
    "### Then perform cross validation according given problem statement metric and further process is same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076dc7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10bf8ebb",
   "metadata": {},
   "source": [
    "# Important Points to be Note:-\n",
    "    \n",
    "1) Apply single scaler to scaler all numeric values. All values should be scaled in a specific range no matter whether they are continuous numeric values or discrete or binary numeric values.\n",
    "\n",
    "\n",
    "2) After converting all categorical variables to numerical, split the data and check the distribution of all variables whether they are continuous or discrete, if the skewness is present in the variables, apply transformation techniques to normally distributed the variables. Check the skewness in only independent variables. After transformation, scale the data. If the skewness is present in the variables the majority values biased the model, because our model learn on the majority values. So, in future if values of independent variable are not same as majority class in which the model is trainned, it will not provide better results. \n",
    "\n",
    "\n",
    "3) Check outliers before filling null values treat them if you don't want data analysis otherwise treat outliers before converting categorical data into numerical. It is also depend on the strategy of model building.\n",
    "\n",
    "\n",
    "4) If two independent variables are highly correlated than check the correlation of each variable with target variabe and which variable has the lowest correlation with target variable, drop it.\n",
    "\n",
    "\n",
    "5) While perfroming EDA write inplace=True in your codes, otherwise the thing you want to perfrom, it will done only on temporary basis or varible of EDA not on original dataset.\n",
    "\n",
    "\n",
    "6) It is important to use the same scaling method for both the training and test sets. This will ensure that the data is scaled consistently.\n",
    "\n",
    "\n",
    "7) If features are not normally distributed transformation is not required in classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec9c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d12edf96",
   "metadata": {},
   "source": [
    "### Q) Why we drop highly correlated and multi-correlated variables for model building in ML?\n",
    "\n",
    "**`Reduces model complexity`**: When two features are highly correlated, they essentially contain the same information. This means that the model doesn't need to learn both features, because it can learn everything it needs to know from just one of them. This makes the model simpler and easier to understand.\n",
    "\n",
    "**`Avoids overfitting`**: Overfitting happens when the model learns the training data too well, and as a result, it doesn't generalize well to new data. This can happen when the model has too many features, including highly correlated features. By removing these features, we can help to prevent overfitting.\n",
    "\n",
    "\n",
    "**`Avoiding multicollinearity`**: Multicollinearity is a problem that can occur when two or more predictor variables in a dataset are highly correlated with each other. This can make it difficult for the model to learn from the data, and it can also lead to unstable results. By removing correlated features, we can help to avoid this problem.\n",
    "\n",
    "\n",
    "**`Improving model performance`**: Highly correlated variables can introduce unnecessary complexity into the model, which can negatively impact its performance. By removing these variables, we can simplify the model, reduce the dimensionality of the feature space, and potentially improve the model's performance.\n",
    "\n",
    "\n",
    "**`NOTE`**: It is a good practice to drop highly correlated features from machine learning models. This can help to improve the model's performance, prevent overfitting, and avoid multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4d65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06dd8b2d",
   "metadata": {},
   "source": [
    "### Q) What is robust scaler?\n",
    "\n",
    "* Robust scaler is used to scale and chane the range of data within a specific range. We usually use robust scaler when data set contains outliers and we don't want to remove outliers.\n",
    "\n",
    "\n",
    "* Robust scaler subtract each data point by the median of data and divide by interquartile range.\n",
    "\n",
    "\n",
    "* Formula of robust scaler is Robust_Scaled_Value = (X - median(X)) / (Q3(X) - Q1(X)).\n",
    "\n",
    "\n",
    "* The range of the robust scaler is not fixed it depends on the nature of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2321fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ff5bd05",
   "metadata": {},
   "source": [
    "### Q) Can we scale the target variable?\n",
    "\n",
    "We should not scale the target variable (the variable that we are trying to predict). This is because the target variable is what we are trying to learn from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40deca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba204497",
   "metadata": {},
   "source": [
    "### Q) When to use get dummies methods, label encoder and target mean encoding?\n",
    "\n",
    "Using a specific encoding technique will depends on the nature of data.\n",
    "\n",
    "* When we have nomial categorical variable, it is recommended to use one hot encoding or get_dummies method.\n",
    "\n",
    "\n",
    "* When we have ordinal categorical variable, it is recommended to use Label encoder or df.replace() method.\n",
    "\n",
    "\n",
    "* When we have multiple unique categories in the variable, such as location. It is recoomended to use target mean encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49872fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3dd3a9b",
   "metadata": {},
   "source": [
    "### Q) Can we apply same Encoding to encode all variable?\n",
    "\n",
    "* No, it is not recommended to use same encosing technique for all variables. We can use multiple encoding techniques in a dateset it depends on the nature of variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2723a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27aa09d1",
   "metadata": {},
   "source": [
    "### Q) Can we apply same Scaling Method for all variables?\n",
    "\n",
    "* Yes, it is recommended to use same scaler because we want the range of all variables to be same. If the variable is already is the same range so we can not scale them i.e binary variables. Eg: we have any binary variable so we can not scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df109f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a19c5c32",
   "metadata": {},
   "source": [
    "### Q) What is disadvantage of get_dummies method or One hot encoding?\n",
    "By using get_dummies or One Hot Encoding method the number of variables will increase. Eg: we have 4 categories in a column so it will make 4 column, 1 column for each category, and we genrally remove any 1 column so, we have total 3 columns. Due to more number of columns the chances of overfitting will increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805ab6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55ffd7f0",
   "metadata": {},
   "source": [
    "### When to use StandardScaler:\n",
    "\n",
    "When the features are normally distributed.\n",
    "\n",
    "When the features have different scales.\n",
    "\n",
    "When you want to improve the performance of algorithms that are sensitive to the scale of the features, such as linear regression and logistic regression.\n",
    "\n",
    "### When to use MinMaxScaler:\n",
    "\n",
    "When the features are not normally distributed.\n",
    "\n",
    "When you want to ensure that the features have a minimum value of 0 and a maximum value of 1.\n",
    "\n",
    "When you want to improve the performance of algorithms that are not sensitive to the scale of the features, such as decision trees and support vector machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf10d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3145f6e",
   "metadata": {},
   "source": [
    "### Q) What is MDD?\n",
    "\n",
    "MDD stands for Model Development Document.\n",
    "\n",
    "A model development document is a detailed report that documents the process of developing a machine learning model. It provides a comprehensive overview of the model development process, from data collection and preprocessing to model selection and evaluation.\n",
    "\n",
    "Here are some sections that may be included in a model development document:\n",
    "\n",
    "1) Introduction: This section provides an overview of the project and the problem that the model is intended to solve.\n",
    "\n",
    "\n",
    "2) Data Collection and Preprocessing: This section outlines the data collection process and describes how the data was cleaned, preprocessed, and transformed for use in the model. It may also describe any feature engineering techniques that were used to create new features.\n",
    "\n",
    "\n",
    "3) Exploratory Data Analysis (EDA): This section describes the process of exploring the data to gain insights and identify any patterns or relationships between variables. It may include visualizations of the data and statistical analyses.\n",
    "\n",
    "\n",
    "4) Model Selection: This section outlines the process of selecting the appropriate machine learning model for the problem at hand. It may include a comparison of different algorithms, as well as a discussion of the advantages and disadvantages of each.\n",
    "\n",
    "\n",
    "5) Model Training: This section describes the process of training the model using the data. It may include a description of the hyperparameters used, as well as any cross-validation or regularization techniques employed.\n",
    "\n",
    "\n",
    "6) Model Evaluation: This section outlines how the performance of the model was evaluated. It may include metrics such as accuracy, precision, recall, and F1 score, as well as visualizations of the results.\n",
    "\n",
    "\n",
    "7) Results and Discussion: This section summarizes the results of the model and discusses its strengths and limitations. It may also include recommendations for future work and improvements to the model.\n",
    "\n",
    "\n",
    "8) Conclusion: This section provides a brief summary of the project and the model developed, as well as any final thoughts or recommendations.\n",
    "\n",
    "Overall, a model development document serves as a record of the model development process and can be used to communicate the results of the project to stakeholders. It can also be used to reproduce the results in the future, or to build upon the work done to develop the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1291cd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
